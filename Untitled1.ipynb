{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df_tmp=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"Loan_Stats\"]=[1 if x=='Y' else 0 for x in df_tmp[\"Loan_Status\"]]\n",
    "df_tmp=df_tmp.drop(\"Loan_Status\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Loan_ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            df_tmp[label+ \"_is_missing\"]=pd.isnull(content)\n",
    "            df_tmp[label]=content.fillna(content.median())\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            df_tmp[label]=pd.Categorical(content).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        df_tmp[label]=pd.Categorical(content).codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=df_tmp.drop(\"ApplicantIncome\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Self_Employed\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Dependents\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Loan_Amount_Term\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Gender\", axis=1)\n",
    "df_tmp=df_tmp.drop(\"Loan_Amount_Term_is_missing\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "x=df_tmp.drop(\"Loan_Stats\", axis=1).values\n",
    "y=df_tmp[\"Loan_Stats\"].values\n",
    "x_train, x_valid, y_train, y_valid=tts(x,y,test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaledtrain_x = scaler.fit_transform(x_train)\n",
    "scaledvalid_x = scaler.fit_transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(2, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(2, activation='relu'))\n",
    "# model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/400\n",
      "491/491 [==============================] - 1s 1ms/sample - loss: 0.6492 - accuracy: 0.6884 - val_loss: 0.6216 - val_accuracy: 0.6911\n",
      "Epoch 2/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.6329 - accuracy: 0.6864 - val_loss: 0.6083 - val_accuracy: 0.6911\n",
      "Epoch 3/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.6212 - accuracy: 0.6864 - val_loss: 0.6022 - val_accuracy: 0.6911\n",
      "Epoch 4/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.6159 - accuracy: 0.6864 - val_loss: 0.5981 - val_accuracy: 0.6911\n",
      "Epoch 5/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.6126 - accuracy: 0.6864 - val_loss: 0.5962 - val_accuracy: 0.6911\n",
      "Epoch 6/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.6091 - accuracy: 0.6864 - val_loss: 0.5940 - val_accuracy: 0.6911\n",
      "Epoch 7/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.6050 - accuracy: 0.6864 - val_loss: 0.5913 - val_accuracy: 0.6911\n",
      "Epoch 8/400\n",
      "491/491 [==============================] - 0s 106us/sample - loss: 0.6002 - accuracy: 0.6864 - val_loss: 0.5877 - val_accuracy: 0.6911\n",
      "Epoch 9/400\n",
      "491/491 [==============================] - 0s 108us/sample - loss: 0.5951 - accuracy: 0.6864 - val_loss: 0.5841 - val_accuracy: 0.6911\n",
      "Epoch 10/400\n",
      "491/491 [==============================] - 0s 102us/sample - loss: 0.5909 - accuracy: 0.6864 - val_loss: 0.5801 - val_accuracy: 0.6911\n",
      "Epoch 11/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.5862 - accuracy: 0.6864 - val_loss: 0.5749 - val_accuracy: 0.6911\n",
      "Epoch 12/400\n",
      "491/491 [==============================] - 0s 108us/sample - loss: 0.5806 - accuracy: 0.6864 - val_loss: 0.5694 - val_accuracy: 0.6911\n",
      "Epoch 13/400\n",
      "491/491 [==============================] - 0s 96us/sample - loss: 0.5757 - accuracy: 0.6864 - val_loss: 0.5642 - val_accuracy: 0.6911\n",
      "Epoch 14/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.5710 - accuracy: 0.6864 - val_loss: 0.5602 - val_accuracy: 0.6911\n",
      "Epoch 15/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5674 - accuracy: 0.6864 - val_loss: 0.5565 - val_accuracy: 0.6911\n",
      "Epoch 16/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5641 - accuracy: 0.6864 - val_loss: 0.5542 - val_accuracy: 0.6911\n",
      "Epoch 17/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5606 - accuracy: 0.6864 - val_loss: 0.5513 - val_accuracy: 0.6911\n",
      "Epoch 18/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5574 - accuracy: 0.6864 - val_loss: 0.5485 - val_accuracy: 0.6911\n",
      "Epoch 19/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5544 - accuracy: 0.6864 - val_loss: 0.5452 - val_accuracy: 0.6911\n",
      "Epoch 20/400\n",
      "491/491 [==============================] - 0s 88us/sample - loss: 0.5520 - accuracy: 0.6864 - val_loss: 0.5424 - val_accuracy: 0.6911\n",
      "Epoch 21/400\n",
      "491/491 [==============================] - 0s 96us/sample - loss: 0.5489 - accuracy: 0.6864 - val_loss: 0.5397 - val_accuracy: 0.7317\n",
      "Epoch 22/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.5467 - accuracy: 0.7678 - val_loss: 0.5383 - val_accuracy: 0.7724\n",
      "Epoch 23/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5459 - accuracy: 0.7841 - val_loss: 0.5374 - val_accuracy: 0.7724\n",
      "Epoch 24/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.5439 - accuracy: 0.7821 - val_loss: 0.5345 - val_accuracy: 0.7724\n",
      "Epoch 25/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5418 - accuracy: 0.7760 - val_loss: 0.5332 - val_accuracy: 0.7724\n",
      "Epoch 26/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5401 - accuracy: 0.7923 - val_loss: 0.5328 - val_accuracy: 0.7805\n",
      "Epoch 27/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.5385 - accuracy: 0.7943 - val_loss: 0.5310 - val_accuracy: 0.7805\n",
      "Epoch 28/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5371 - accuracy: 0.7943 - val_loss: 0.5294 - val_accuracy: 0.7805\n",
      "Epoch 29/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5351 - accuracy: 0.7984 - val_loss: 0.5285 - val_accuracy: 0.7805\n",
      "Epoch 30/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5337 - accuracy: 0.7984 - val_loss: 0.5270 - val_accuracy: 0.7805\n",
      "Epoch 31/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5325 - accuracy: 0.7984 - val_loss: 0.5257 - val_accuracy: 0.7805\n",
      "Epoch 32/400\n",
      "491/491 [==============================] - 0s 102us/sample - loss: 0.5314 - accuracy: 0.7984 - val_loss: 0.5249 - val_accuracy: 0.7805\n",
      "Epoch 33/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5298 - accuracy: 0.8004 - val_loss: 0.5244 - val_accuracy: 0.7967\n",
      "Epoch 34/400\n",
      "491/491 [==============================] - 0s 102us/sample - loss: 0.5285 - accuracy: 0.8004 - val_loss: 0.5229 - val_accuracy: 0.7967\n",
      "Epoch 35/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5273 - accuracy: 0.8024 - val_loss: 0.5219 - val_accuracy: 0.7967\n",
      "Epoch 36/400\n",
      "491/491 [==============================] - 0s 99us/sample - loss: 0.5265 - accuracy: 0.8024 - val_loss: 0.5207 - val_accuracy: 0.7967\n",
      "Epoch 37/400\n",
      "491/491 [==============================] - 0s 102us/sample - loss: 0.5261 - accuracy: 0.8045 - val_loss: 0.5206 - val_accuracy: 0.8049\n",
      "Epoch 38/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.5249 - accuracy: 0.8045 - val_loss: 0.5191 - val_accuracy: 0.8049\n",
      "Epoch 39/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5232 - accuracy: 0.8065 - val_loss: 0.5188 - val_accuracy: 0.8049\n",
      "Epoch 40/400\n",
      "491/491 [==============================] - 0s 100us/sample - loss: 0.5226 - accuracy: 0.8106 - val_loss: 0.5185 - val_accuracy: 0.8130\n",
      "Epoch 41/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.5216 - accuracy: 0.8106 - val_loss: 0.5175 - val_accuracy: 0.8130\n",
      "Epoch 42/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.5209 - accuracy: 0.8106 - val_loss: 0.5178 - val_accuracy: 0.8130\n",
      "Epoch 43/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.5201 - accuracy: 0.8126 - val_loss: 0.5166 - val_accuracy: 0.8130\n",
      "Epoch 44/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.5193 - accuracy: 0.8106 - val_loss: 0.5151 - val_accuracy: 0.8130\n",
      "Epoch 45/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5188 - accuracy: 0.8126 - val_loss: 0.5164 - val_accuracy: 0.8130\n",
      "Epoch 46/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5172 - accuracy: 0.8147 - val_loss: 0.5148 - val_accuracy: 0.8130\n",
      "Epoch 47/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5166 - accuracy: 0.8106 - val_loss: 0.5138 - val_accuracy: 0.8130\n",
      "Epoch 48/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5163 - accuracy: 0.8106 - val_loss: 0.5144 - val_accuracy: 0.8130\n",
      "Epoch 49/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.5150 - accuracy: 0.8106 - val_loss: 0.5135 - val_accuracy: 0.8130\n",
      "Epoch 50/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5145 - accuracy: 0.8106 - val_loss: 0.5125 - val_accuracy: 0.8130\n",
      "Epoch 51/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.5139 - accuracy: 0.8106 - val_loss: 0.5119 - val_accuracy: 0.8130\n",
      "Epoch 52/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5122 - accuracy: 0.8147 - val_loss: 0.5163 - val_accuracy: 0.8049\n",
      "Epoch 53/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.5128 - accuracy: 0.8147 - val_loss: 0.5152 - val_accuracy: 0.7967\n",
      "Epoch 54/400\n",
      "491/491 [==============================] - 0s 104us/sample - loss: 0.5116 - accuracy: 0.8147 - val_loss: 0.5117 - val_accuracy: 0.8130\n",
      "Epoch 55/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5108 - accuracy: 0.8147 - val_loss: 0.5112 - val_accuracy: 0.8130\n",
      "Epoch 56/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 95us/sample - loss: 0.5101 - accuracy: 0.8147 - val_loss: 0.5122 - val_accuracy: 0.8130\n",
      "Epoch 57/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5099 - accuracy: 0.8147 - val_loss: 0.5114 - val_accuracy: 0.8130\n",
      "Epoch 58/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.5097 - accuracy: 0.8106 - val_loss: 0.5101 - val_accuracy: 0.8130\n",
      "Epoch 59/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.5083 - accuracy: 0.8147 - val_loss: 0.5092 - val_accuracy: 0.8130\n",
      "Epoch 60/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5083 - accuracy: 0.8147 - val_loss: 0.5098 - val_accuracy: 0.8049\n",
      "Epoch 61/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.5075 - accuracy: 0.8147 - val_loss: 0.5114 - val_accuracy: 0.7967\n",
      "Epoch 62/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5073 - accuracy: 0.8147 - val_loss: 0.5078 - val_accuracy: 0.8130\n",
      "Epoch 63/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.5062 - accuracy: 0.8147 - val_loss: 0.5107 - val_accuracy: 0.7967\n",
      "Epoch 64/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.5057 - accuracy: 0.8147 - val_loss: 0.5088 - val_accuracy: 0.7967\n",
      "Epoch 65/400\n",
      "491/491 [==============================] - 0s 100us/sample - loss: 0.5055 - accuracy: 0.8147 - val_loss: 0.5078 - val_accuracy: 0.8049\n",
      "Epoch 66/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.5046 - accuracy: 0.8147 - val_loss: 0.5104 - val_accuracy: 0.7967\n",
      "Epoch 67/400\n",
      "491/491 [==============================] - 0s 100us/sample - loss: 0.5039 - accuracy: 0.8147 - val_loss: 0.5092 - val_accuracy: 0.7967\n",
      "Epoch 68/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.5036 - accuracy: 0.8147 - val_loss: 0.5062 - val_accuracy: 0.8049\n",
      "Epoch 69/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.5033 - accuracy: 0.8126 - val_loss: 0.5097 - val_accuracy: 0.7967\n",
      "Epoch 70/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.5025 - accuracy: 0.8147 - val_loss: 0.5071 - val_accuracy: 0.7967\n",
      "Epoch 71/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.5015 - accuracy: 0.8147 - val_loss: 0.5065 - val_accuracy: 0.7967\n",
      "Epoch 72/400\n",
      "491/491 [==============================] - 0s 104us/sample - loss: 0.5026 - accuracy: 0.8147 - val_loss: 0.5057 - val_accuracy: 0.7967\n",
      "Epoch 73/400\n",
      "491/491 [==============================] - 0s 114us/sample - loss: 0.5007 - accuracy: 0.8147 - val_loss: 0.5064 - val_accuracy: 0.7967\n",
      "Epoch 74/400\n",
      "491/491 [==============================] - 0s 104us/sample - loss: 0.5017 - accuracy: 0.8126 - val_loss: 0.5040 - val_accuracy: 0.7967\n",
      "Epoch 75/400\n",
      "491/491 [==============================] - 0s 104us/sample - loss: 0.5008 - accuracy: 0.8126 - val_loss: 0.5081 - val_accuracy: 0.7967\n",
      "Epoch 76/400\n",
      "491/491 [==============================] - 0s 106us/sample - loss: 0.4990 - accuracy: 0.8147 - val_loss: 0.5054 - val_accuracy: 0.7967\n",
      "Epoch 77/400\n",
      "491/491 [==============================] - 0s 106us/sample - loss: 0.4989 - accuracy: 0.8147 - val_loss: 0.5045 - val_accuracy: 0.7967\n",
      "Epoch 78/400\n",
      "491/491 [==============================] - 0s 100us/sample - loss: 0.4996 - accuracy: 0.8106 - val_loss: 0.5027 - val_accuracy: 0.7967\n",
      "Epoch 79/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.4978 - accuracy: 0.8167 - val_loss: 0.5068 - val_accuracy: 0.7967\n",
      "Epoch 80/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4972 - accuracy: 0.8167 - val_loss: 0.5091 - val_accuracy: 0.7967\n",
      "Epoch 81/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4975 - accuracy: 0.8167 - val_loss: 0.5046 - val_accuracy: 0.7967\n",
      "Epoch 82/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4961 - accuracy: 0.8147 - val_loss: 0.5089 - val_accuracy: 0.7886\n",
      "Epoch 83/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4963 - accuracy: 0.8167 - val_loss: 0.5046 - val_accuracy: 0.7967\n",
      "Epoch 84/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4961 - accuracy: 0.8167 - val_loss: 0.5070 - val_accuracy: 0.7886\n",
      "Epoch 85/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4951 - accuracy: 0.8167 - val_loss: 0.5084 - val_accuracy: 0.7886\n",
      "Epoch 86/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4943 - accuracy: 0.8167 - val_loss: 0.5067 - val_accuracy: 0.7886\n",
      "Epoch 87/400\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.4938 - accuracy: 0.8167 - val_loss: 0.5042 - val_accuracy: 0.7886\n",
      "Epoch 88/400\n",
      "491/491 [==============================] - 0s 79us/sample - loss: 0.4938 - accuracy: 0.8167 - val_loss: 0.5043 - val_accuracy: 0.7886\n",
      "Epoch 89/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4931 - accuracy: 0.8167 - val_loss: 0.5071 - val_accuracy: 0.7967\n",
      "Epoch 90/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4927 - accuracy: 0.8167 - val_loss: 0.5089 - val_accuracy: 0.8049\n",
      "Epoch 91/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4924 - accuracy: 0.8167 - val_loss: 0.5053 - val_accuracy: 0.7886\n",
      "Epoch 92/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4932 - accuracy: 0.8167 - val_loss: 0.5022 - val_accuracy: 0.7886\n",
      "Epoch 93/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4917 - accuracy: 0.8147 - val_loss: 0.5051 - val_accuracy: 0.7886\n",
      "Epoch 94/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4910 - accuracy: 0.8167 - val_loss: 0.5058 - val_accuracy: 0.8049\n",
      "Epoch 95/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4906 - accuracy: 0.8167 - val_loss: 0.5059 - val_accuracy: 0.8049\n",
      "Epoch 96/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4918 - accuracy: 0.8167 - val_loss: 0.5055 - val_accuracy: 0.8049\n",
      "Epoch 97/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.4900 - accuracy: 0.8167 - val_loss: 0.5065 - val_accuracy: 0.8049\n",
      "Epoch 98/400\n",
      "491/491 [==============================] - 0s 99us/sample - loss: 0.4900 - accuracy: 0.8167 - val_loss: 0.5061 - val_accuracy: 0.8049\n",
      "Epoch 99/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4903 - accuracy: 0.8167 - val_loss: 0.5040 - val_accuracy: 0.8049\n",
      "Epoch 100/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.4887 - accuracy: 0.8167 - val_loss: 0.5093 - val_accuracy: 0.8049\n",
      "Epoch 101/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4889 - accuracy: 0.8167 - val_loss: 0.5089 - val_accuracy: 0.8049\n",
      "Epoch 102/400\n",
      "491/491 [==============================] - 0s 86us/sample - loss: 0.4888 - accuracy: 0.8167 - val_loss: 0.5089 - val_accuracy: 0.8049\n",
      "Epoch 103/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4882 - accuracy: 0.8167 - val_loss: 0.5055 - val_accuracy: 0.8049\n",
      "Epoch 104/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4877 - accuracy: 0.8167 - val_loss: 0.5059 - val_accuracy: 0.8049\n",
      "Epoch 105/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4874 - accuracy: 0.8167 - val_loss: 0.5044 - val_accuracy: 0.8049\n",
      "Epoch 106/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4870 - accuracy: 0.8167 - val_loss: 0.5054 - val_accuracy: 0.8049\n",
      "Epoch 107/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4874 - accuracy: 0.8147 - val_loss: 0.5024 - val_accuracy: 0.8049\n",
      "Epoch 108/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4871 - accuracy: 0.8167 - val_loss: 0.5090 - val_accuracy: 0.8049\n",
      "Epoch 109/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4864 - accuracy: 0.8147 - val_loss: 0.5016 - val_accuracy: 0.8049\n",
      "Epoch 110/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4867 - accuracy: 0.8167 - val_loss: 0.5056 - val_accuracy: 0.8049\n",
      "Epoch 111/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4854 - accuracy: 0.8167 - val_loss: 0.5008 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/400\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.4872 - accuracy: 0.8167 - val_loss: 0.5061 - val_accuracy: 0.8049\n",
      "Epoch 113/400\n",
      "491/491 [==============================] - 0s 94us/sample - loss: 0.4852 - accuracy: 0.8147 - val_loss: 0.5009 - val_accuracy: 0.8049\n",
      "Epoch 114/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4848 - accuracy: 0.8147 - val_loss: 0.4997 - val_accuracy: 0.8049\n",
      "Epoch 115/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4843 - accuracy: 0.8147 - val_loss: 0.5012 - val_accuracy: 0.7967\n",
      "Epoch 116/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4836 - accuracy: 0.8147 - val_loss: 0.5044 - val_accuracy: 0.8049\n",
      "Epoch 117/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4837 - accuracy: 0.8147 - val_loss: 0.5057 - val_accuracy: 0.8049\n",
      "Epoch 118/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4834 - accuracy: 0.8126 - val_loss: 0.5024 - val_accuracy: 0.8049\n",
      "Epoch 119/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4832 - accuracy: 0.8147 - val_loss: 0.5049 - val_accuracy: 0.8049\n",
      "Epoch 120/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4824 - accuracy: 0.8126 - val_loss: 0.5011 - val_accuracy: 0.8049\n",
      "Epoch 121/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4824 - accuracy: 0.8147 - val_loss: 0.5045 - val_accuracy: 0.8049\n",
      "Epoch 122/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.4818 - accuracy: 0.8147 - val_loss: 0.5050 - val_accuracy: 0.8049\n",
      "Epoch 123/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4822 - accuracy: 0.8147 - val_loss: 0.5008 - val_accuracy: 0.8049\n",
      "Epoch 124/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4814 - accuracy: 0.8147 - val_loss: 0.5039 - val_accuracy: 0.8049\n",
      "Epoch 125/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4809 - accuracy: 0.8147 - val_loss: 0.5035 - val_accuracy: 0.8049\n",
      "Epoch 126/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4809 - accuracy: 0.8126 - val_loss: 0.5034 - val_accuracy: 0.8130\n",
      "Epoch 127/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4817 - accuracy: 0.8147 - val_loss: 0.5047 - val_accuracy: 0.8049\n",
      "Epoch 128/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4805 - accuracy: 0.8147 - val_loss: 0.5021 - val_accuracy: 0.8049\n",
      "Epoch 129/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4798 - accuracy: 0.8126 - val_loss: 0.5013 - val_accuracy: 0.8049\n",
      "Epoch 130/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4798 - accuracy: 0.8126 - val_loss: 0.5000 - val_accuracy: 0.8049\n",
      "Epoch 131/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4799 - accuracy: 0.8126 - val_loss: 0.5001 - val_accuracy: 0.8049\n",
      "Epoch 132/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4793 - accuracy: 0.8126 - val_loss: 0.5006 - val_accuracy: 0.8049\n",
      "Epoch 133/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4788 - accuracy: 0.8126 - val_loss: 0.5023 - val_accuracy: 0.8049\n",
      "Epoch 134/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4796 - accuracy: 0.8126 - val_loss: 0.4992 - val_accuracy: 0.8049\n",
      "Epoch 135/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4783 - accuracy: 0.8147 - val_loss: 0.5041 - val_accuracy: 0.8049\n",
      "Epoch 136/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4783 - accuracy: 0.8147 - val_loss: 0.5021 - val_accuracy: 0.8049\n",
      "Epoch 137/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.4778 - accuracy: 0.8147 - val_loss: 0.5030 - val_accuracy: 0.8049\n",
      "Epoch 138/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4775 - accuracy: 0.8147 - val_loss: 0.5020 - val_accuracy: 0.8130\n",
      "Epoch 139/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4771 - accuracy: 0.8147 - val_loss: 0.5009 - val_accuracy: 0.8130\n",
      "Epoch 140/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4769 - accuracy: 0.8167 - val_loss: 0.5044 - val_accuracy: 0.8049\n",
      "Epoch 141/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4769 - accuracy: 0.8147 - val_loss: 0.5025 - val_accuracy: 0.8049\n",
      "Epoch 142/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4761 - accuracy: 0.8167 - val_loss: 0.5048 - val_accuracy: 0.8049\n",
      "Epoch 143/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.4764 - accuracy: 0.8167 - val_loss: 0.5044 - val_accuracy: 0.8049\n",
      "Epoch 144/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.4755 - accuracy: 0.8167 - val_loss: 0.4989 - val_accuracy: 0.8130\n",
      "Epoch 145/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.4757 - accuracy: 0.8147 - val_loss: 0.4999 - val_accuracy: 0.8130\n",
      "Epoch 146/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4755 - accuracy: 0.8167 - val_loss: 0.5052 - val_accuracy: 0.8049\n",
      "Epoch 147/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4753 - accuracy: 0.8167 - val_loss: 0.5001 - val_accuracy: 0.8130\n",
      "Epoch 148/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4750 - accuracy: 0.8147 - val_loss: 0.5038 - val_accuracy: 0.8130\n",
      "Epoch 149/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4743 - accuracy: 0.8167 - val_loss: 0.5014 - val_accuracy: 0.8130\n",
      "Epoch 150/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.4744 - accuracy: 0.8147 - val_loss: 0.5016 - val_accuracy: 0.8130\n",
      "Epoch 151/400\n",
      "491/491 [==============================] - 0s 90us/sample - loss: 0.4741 - accuracy: 0.8147 - val_loss: 0.4988 - val_accuracy: 0.8130\n",
      "Epoch 152/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4743 - accuracy: 0.8147 - val_loss: 0.5020 - val_accuracy: 0.8130\n",
      "Epoch 153/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4738 - accuracy: 0.8147 - val_loss: 0.5029 - val_accuracy: 0.8130\n",
      "Epoch 154/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.4733 - accuracy: 0.8147 - val_loss: 0.4989 - val_accuracy: 0.8130\n",
      "Epoch 155/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4734 - accuracy: 0.8147 - val_loss: 0.5017 - val_accuracy: 0.8130\n",
      "Epoch 156/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4733 - accuracy: 0.8167 - val_loss: 0.5036 - val_accuracy: 0.8130\n",
      "Epoch 157/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4728 - accuracy: 0.8147 - val_loss: 0.5009 - val_accuracy: 0.8130\n",
      "Epoch 158/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4723 - accuracy: 0.8147 - val_loss: 0.5012 - val_accuracy: 0.8130\n",
      "Epoch 159/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4726 - accuracy: 0.8147 - val_loss: 0.5021 - val_accuracy: 0.8049\n",
      "Epoch 160/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4725 - accuracy: 0.8147 - val_loss: 0.5001 - val_accuracy: 0.8130\n",
      "Epoch 161/400\n",
      "491/491 [==============================] - 0s 86us/sample - loss: 0.4723 - accuracy: 0.8147 - val_loss: 0.5001 - val_accuracy: 0.8130\n",
      "Epoch 162/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4726 - accuracy: 0.8167 - val_loss: 0.5050 - val_accuracy: 0.8049\n",
      "Epoch 163/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4717 - accuracy: 0.8147 - val_loss: 0.4963 - val_accuracy: 0.8130\n",
      "Epoch 164/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4715 - accuracy: 0.8147 - val_loss: 0.5002 - val_accuracy: 0.8130\n",
      "Epoch 165/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4715 - accuracy: 0.8167 - val_loss: 0.5072 - val_accuracy: 0.7967\n",
      "Epoch 166/400\n",
      "491/491 [==============================] - 0s 81us/sample - loss: 0.4716 - accuracy: 0.8167 - val_loss: 0.4998 - val_accuracy: 0.8049\n",
      "Epoch 167/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4711 - accuracy: 0.8167 - val_loss: 0.5064 - val_accuracy: 0.7967\n",
      "Epoch 168/400\n",
      "491/491 [==============================] - 0s 91us/sample - loss: 0.4707 - accuracy: 0.8167 - val_loss: 0.5033 - val_accuracy: 0.8049\n",
      "Epoch 169/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4706 - accuracy: 0.8167 - val_loss: 0.5024 - val_accuracy: 0.8049\n",
      "Epoch 170/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4705 - accuracy: 0.8167 - val_loss: 0.5052 - val_accuracy: 0.8049\n",
      "Epoch 171/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4699 - accuracy: 0.8167 - val_loss: 0.5020 - val_accuracy: 0.8049\n",
      "Epoch 172/400\n",
      "491/491 [==============================] - 0s 83us/sample - loss: 0.4699 - accuracy: 0.8167 - val_loss: 0.5020 - val_accuracy: 0.8049\n",
      "Epoch 173/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4700 - accuracy: 0.8147 - val_loss: 0.4968 - val_accuracy: 0.8130\n",
      "Epoch 174/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4693 - accuracy: 0.8147 - val_loss: 0.5046 - val_accuracy: 0.8049\n",
      "Epoch 175/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4694 - accuracy: 0.8167 - val_loss: 0.5055 - val_accuracy: 0.7967\n",
      "Epoch 176/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4690 - accuracy: 0.8167 - val_loss: 0.5041 - val_accuracy: 0.8049\n",
      "Epoch 177/400\n",
      "491/491 [==============================] - 0s 95us/sample - loss: 0.4701 - accuracy: 0.8147 - val_loss: 0.4993 - val_accuracy: 0.8049\n",
      "Epoch 178/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4684 - accuracy: 0.8147 - val_loss: 0.5087 - val_accuracy: 0.7967\n",
      "Epoch 179/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4691 - accuracy: 0.8167 - val_loss: 0.5091 - val_accuracy: 0.7967\n",
      "Epoch 180/400\n",
      "491/491 [==============================] - 0s 89us/sample - loss: 0.4685 - accuracy: 0.8167 - val_loss: 0.5027 - val_accuracy: 0.8049\n",
      "Epoch 181/400\n",
      "491/491 [==============================] - 0s 88us/sample - loss: 0.4683 - accuracy: 0.8147 - val_loss: 0.5039 - val_accuracy: 0.8049\n",
      "Epoch 182/400\n",
      "491/491 [==============================] - 0s 85us/sample - loss: 0.4682 - accuracy: 0.8147 - val_loss: 0.5011 - val_accuracy: 0.8049\n",
      "Epoch 183/400\n",
      "491/491 [==============================] - 0s 87us/sample - loss: 0.4682 - accuracy: 0.8147 - val_loss: 0.4967 - val_accuracy: 0.8130\n",
      "Epoch 184/400\n",
      "491/491 [==============================] - 0s 102us/sample - loss: 0.4680 - accuracy: 0.8147 - val_loss: 0.5014 - val_accuracy: 0.8049\n",
      "Epoch 185/400\n",
      "491/491 [==============================] - 0s 96us/sample - loss: 0.4685 - accuracy: 0.8167 - val_loss: 0.5098 - val_accuracy: 0.7967\n",
      "Epoch 186/400\n",
      "491/491 [==============================] - 0s 93us/sample - loss: 0.4682 - accuracy: 0.8167 - val_loss: 0.5015 - val_accuracy: 0.8049\n",
      "Epoch 187/400\n",
      "491/491 [==============================] - 0s 98us/sample - loss: 0.4672 - accuracy: 0.8167 - val_loss: 0.5045 - val_accuracy: 0.8049\n",
      "Epoch 188/400\n",
      "491/491 [==============================] - 0s 97us/sample - loss: 0.4679 - accuracy: 0.8147 - val_loss: 0.5039 - val_accuracy: 0.8049\n",
      "Epoch 00188: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x189abe30a88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaledtrain_x,\n",
    "          y=y_train,\n",
    "          epochs=400,\n",
    "          validation_data=(scaledvalid_x, y_valid),\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
